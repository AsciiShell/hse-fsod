{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab72cefa-38ae-4428-9b30-f14f0a32ad99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:39:56.134950Z",
     "iopub.status.busy": "2022-04-10T19:39:56.134152Z",
     "iopub.status.idle": "2022-04-10T19:39:56.144414Z",
     "shell.execute_reply": "2022-04-10T19:39:56.143479Z",
     "shell.execute_reply.started": "2022-04-10T19:39:56.134845Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff36b7b-bd9d-4461-bf61-934254a42e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:39:56.715186Z",
     "iopub.status.busy": "2022-04-10T19:39:56.712701Z",
     "iopub.status.idle": "2022-04-10T19:39:58.182788Z",
     "shell.execute_reply": "2022-04-10T19:39:58.182182Z",
     "shell.execute_reply.started": "2022-04-10T19:39:56.715036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# from annoy import AnnoyIndex\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9bb707-58b6-47cf-a61e-d7ee293f7483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:39:58.184142Z",
     "iopub.status.busy": "2022-04-10T19:39:58.183871Z",
     "iopub.status.idle": "2022-04-10T19:39:58.839847Z",
     "shell.execute_reply": "2022-04-10T19:39:58.839159Z",
     "shell.execute_reply.started": "2022-04-10T19:39:58.184117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.common import AutoShape, DetectMultiBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfd7c8a-fd63-4ec7-9adb-8b7c67533e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:39:58.841623Z",
     "iopub.status.busy": "2022-04-10T19:39:58.840879Z",
     "iopub.status.idle": "2022-04-10T19:39:59.496684Z",
     "shell.execute_reply": "2022-04-10T19:39:59.496028Z",
     "shell.execute_reply.started": "2022-04-10T19:39:58.841541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = AutoShape(DetectMultiBackend(\"./models/yolov5m.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38bb5e5e-70be-4a31-89d3-49313de20abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:40:22.104903Z",
     "iopub.status.busy": "2022-04-10T19:40:22.104528Z",
     "iopub.status.idle": "2022-04-10T19:40:22.112452Z",
     "shell.execute_reply": "2022-04-10T19:40:22.111538Z",
     "shell.execute_reply.started": "2022-04-10T19:40:22.104870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/custom/images/00000001_020.jpeg',\n",
       " './datasets/custom/images/00000001_008.jpeg',\n",
       " './datasets/custom/images/00000001_012.jpeg',\n",
       " './datasets/custom/images/00000001_000.jpeg',\n",
       " './datasets/custom/images/00000001_005.jpeg',\n",
       " './datasets/custom/images/00000001_024.jpeg',\n",
       " './datasets/custom/images/00000001_017.jpeg',\n",
       " './datasets/custom/images/00000001_011.jpeg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"./datasets/custom/images/\"\n",
    "images = [root + x for x in os.listdir(root)]\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d362f8-3e8f-46e4-9024-097d8915f6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:40:22.262616Z",
     "iopub.status.busy": "2022-04-10T19:40:22.262104Z",
     "iopub.status.idle": "2022-04-10T19:40:22.267522Z",
     "shell.execute_reply": "2022-04-10T19:40:22.266643Z",
     "shell.execute_reply.started": "2022-04-10T19:40:22.262584Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jupyter_innotater as ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b1fe0c9-d0c2-4c6f-b3e1-37ec6cbe32dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:56:05.153195Z",
     "iopub.status.busy": "2022-04-10T19:56:05.152748Z",
     "iopub.status.idle": "2022-04-10T19:56:05.163327Z",
     "shell.execute_reply": "2022-04-10T19:56:05.161681Z",
     "shell.execute_reply.started": "2022-04-10T19:56:05.153141Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeats = 4\n",
    "\n",
    "breeds = ['cat_{}'.format(x) for x in range(repeats)]\n",
    "targets_exclude = np.zeros((len(images), 1), dtype='int')\n",
    "targets_breed = np.zeros((len(images), len(breeds)), dtype='int')\n",
    "targets_bboxes = np.zeros((len(images), repeats, 4), dtype='int') # (x,y,w,h) for each animal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "670dedde-cc4f-405f-8689-20e9444c4765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:56:45.664506Z",
     "iopub.status.busy": "2022-04-10T19:56:45.664193Z",
     "iopub.status.idle": "2022-04-10T19:56:45.791435Z",
     "shell.execute_reply": "2022-04-10T19:56:45.790922Z",
     "shell.execute_reply.started": "2022-04-10T19:56:45.664472Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5ed6da34af455ab3e991176561f3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ji.Innotater(\n",
    "    [\n",
    "        ji.ImageInnotation(images), # Display the image itself\n",
    "        ji.TextInnotation(images, multiline=False) # Display the image filename\n",
    "    ],\n",
    "    [\n",
    "        ji.BinaryClassInnotation(targets_exclude, name='Exclude'), # Checkbox\n",
    "        ji.RepeatInnotation(\n",
    "            (ji.BoundingBoxInnotation, targets_bboxes), # Individual animal bounding box\n",
    "            (ji.MultiClassInnotation, targets_breed,\n",
    "                {'name':'Breed', 'classes':breeds, 'dropdown':True}), # Per-animal breed dropdown\n",
    "            max_repeats=repeats, min_repeats=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48e47090-6731-417d-98c1-3ec736567c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:33:43.160554Z",
     "iopub.status.busy": "2022-04-10T21:33:43.160180Z",
     "iopub.status.idle": "2022-04-10T21:33:43.166828Z",
     "shell.execute_reply": "2022-04-10T21:33:43.165951Z",
     "shell.execute_reply.started": "2022-04-10T21:33:43.160515Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bbox2xywh(bbox, size):\n",
    "    x = (bbox[0] + bbox[1]) / 2.0\n",
    "    y = (bbox[2] + bbox[3]) / 2.0\n",
    "    w = np.abs(bbox[1] - bbox[0])\n",
    "    h = np.abs(bbox[3] - bbox[2])\n",
    "    x = x / size[1]\n",
    "    w = w / size[1]\n",
    "    y = y / size[0]\n",
    "    h = h / size[0]\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59aded89-6f3a-4edb-b3ae-0b2ce69cff99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:33:43.781096Z",
     "iopub.status.busy": "2022-04-10T21:33:43.779810Z",
     "iopub.status.idle": "2022-04-10T21:33:43.916563Z",
     "shell.execute_reply": "2022-04-10T21:33:43.915848Z",
     "shell.execute_reply.started": "2022-04-10T21:33:43.780994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for im, bboxs in zip(images, targets_bboxes):\n",
    "    annotation = '.'.join(im.replace('/images/', '/labels/').split('.')[:-1]) + '.txt'\n",
    "    image = cv2.imread(im, cv2.IMREAD_COLOR)\n",
    "    with open(annotation, 'wt') as f:\n",
    "        for bbox in bboxs:\n",
    "            if bbox.sum() == 0:\n",
    "                continue\n",
    "            xywh = bbox2xywh(bbox.astype(np.float32), image.shape)\n",
    "            xywh = ' '.join([\"{:.6f}\".format(x) for x in xywh])\n",
    "            f.write('{} {}\\n'.format(15, xywh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0aadf733-1053-4a4c-94d5-a7f6864759a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:33:44.551445Z",
     "iopub.status.busy": "2022-04-10T21:33:44.548131Z",
     "iopub.status.idle": "2022-04-10T21:33:44.594762Z",
     "shell.execute_reply": "2022-04-10T21:33:44.592356Z",
     "shell.execute_reply.started": "2022-04-10T21:33:44.551296Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'path': '../datasets/custom/',\n",
    "    'train': 'images',\n",
    "    'val': 'images',\n",
    "    # 'test': None,\n",
    "    'nc': 80,\n",
    "    'names': ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush'] \n",
    "}\n",
    "# config['names'] = str(config['names'])\n",
    "with open('./config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4797d0a0-3e2a-43d5-8ddf-0ffdf91cc5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:33:47.098230Z",
     "iopub.status.busy": "2022-04-10T21:33:47.095526Z",
     "iopub.status.idle": "2022-04-10T21:35:31.493510Z",
     "shell.execute_reply": "2022-04-10T21:35:31.492063Z",
     "shell.execute_reply.started": "2022-04-10T21:33:47.098059Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=models/yolov5m.pt, cfg=, data=config.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with git@github.com:AsciiShell/yolov5 âœ…\n",
      "YOLOv5 ðŸš€ v6.1-119-gaa542ce torch 1.11.0+cu102 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1    343485  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 369 layers, 21190557 parameters, 21190557 gradients, 49.1 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from models/yolov5m.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/asciishell/projects/hse-fsod/datasets/custom/labels.cache\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 178.72it/s\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/asciishell/projects/hse-fsod/datasets/custom/labels.cache' \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 68.67it/s]  \u001b[0m\n",
      "Plotting labels to yolov5/runs/train/exp9/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.89 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/exp9\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/2        0G    0.1011   0.04882     0.139        21       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8          0          0          0          0          0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/2        0G   0.09568   0.03729    0.1246        12       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8          0          0          0          0          0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/2        0G    0.1071   0.03784    0.1261        16       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8          0          0          0          0          0\n",
      "\n",
      "3 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from yolov5/runs/train/exp9/weights/last.pt, 42.9MB\n",
      "Optimizer stripped from yolov5/runs/train/exp9/weights/best.pt, 42.9MB\n",
      "\n",
      "Validating yolov5/runs/train/exp9/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 21172173 parameters, 0 gradients, 49.0 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8          0          0          0          0          0\n",
      "Results saved to \u001b[1myolov5/runs/train/exp9\u001b[0m\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7ff9db72e9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n"
     ]
    }
   ],
   "source": [
    "!/home/asciishell/projects/hse-fsod/venv/bin/python \\\n",
    "    yolov5/train.py \\\n",
    "    --img 640 \\\n",
    "    --batch 16 \\\n",
    "    --epochs 3 \\\n",
    "    --data config.yaml \\\n",
    "    --weights models/yolov5m.pt \\\n",
    "    --cache \n",
    "    # --freeze 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873714ce-fad6-4bc4-9745-f68be89d1320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YoloV5)",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
