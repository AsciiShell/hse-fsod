{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff36b7b-bd9d-4461-bf61-934254a42e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:08:05.966338Z",
     "iopub.status.busy": "2022-04-14T22:08:05.965316Z",
     "iopub.status.idle": "2022-04-14T22:08:05.980618Z",
     "shell.execute_reply": "2022-04-14T22:08:05.978948Z",
     "shell.execute_reply.started": "2022-04-14T22:08:05.966216Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# from annoy import AnnoyIndex\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9bb707-58b6-47cf-a61e-d7ee293f7483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:08:06.255586Z",
     "iopub.status.busy": "2022-04-14T22:08:06.255283Z",
     "iopub.status.idle": "2022-04-14T22:08:06.259672Z",
     "shell.execute_reply": "2022-04-14T22:08:06.258607Z",
     "shell.execute_reply.started": "2022-04-14T22:08:06.255556Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../yolov5\")\n",
    "from models.common import AutoShape, DetectMultiBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfd7c8a-fd63-4ec7-9adb-8b7c67533e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:08:10.905161Z",
     "iopub.status.busy": "2022-04-14T22:08:10.904153Z",
     "iopub.status.idle": "2022-04-14T22:08:11.467442Z",
     "shell.execute_reply": "2022-04-14T22:08:11.466758Z",
     "shell.execute_reply.started": "2022-04-14T22:08:10.905063Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = AutoShape(DetectMultiBackend(\"../models/yolov5m.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38bb5e5e-70be-4a31-89d3-49313de20abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:10:42.886023Z",
     "iopub.status.busy": "2022-04-14T22:10:42.885645Z",
     "iopub.status.idle": "2022-04-14T22:10:42.894571Z",
     "shell.execute_reply": "2022-04-14T22:10:42.893431Z",
     "shell.execute_reply.started": "2022-04-14T22:10:42.885986Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../datasets/custom/images/00000001_020.jpeg',\n",
       " '../datasets/custom/images/00000001_008.jpeg',\n",
       " '../datasets/custom/images/00000001_012.jpeg',\n",
       " '../datasets/custom/images/00000001_000.jpeg',\n",
       " '../datasets/custom/images/00000001_005.jpeg',\n",
       " '../datasets/custom/images/00000001_024.jpeg',\n",
       " '../datasets/custom/images/00000001_017.jpeg',\n",
       " '../datasets/custom/images/00000001_011.jpeg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"../datasets/custom/images/\"\n",
    "images = [root + x for x in os.listdir(root)]\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d362f8-3e8f-46e4-9024-097d8915f6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:08:31.240933Z",
     "iopub.status.busy": "2022-04-14T22:08:31.240077Z",
     "iopub.status.idle": "2022-04-14T22:08:31.266239Z",
     "shell.execute_reply": "2022-04-14T22:08:31.265209Z",
     "shell.execute_reply.started": "2022-04-14T22:08:31.240846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jupyter_innotater as ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1fe0c9-d0c2-4c6f-b3e1-37ec6cbe32dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:08:31.614336Z",
     "iopub.status.busy": "2022-04-14T22:08:31.614013Z",
     "iopub.status.idle": "2022-04-14T22:08:31.619887Z",
     "shell.execute_reply": "2022-04-14T22:08:31.618974Z",
     "shell.execute_reply.started": "2022-04-14T22:08:31.614304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeats = 4\n",
    "\n",
    "breeds = ['cat_{}'.format(x) for x in range(repeats)]\n",
    "targets_exclude = np.zeros((len(images), 1), dtype='int')\n",
    "targets_breed = np.zeros((len(images), len(breeds)), dtype='int')\n",
    "targets_bboxes = np.zeros((len(images), repeats, 4), dtype='int') # (x,y,w,h) for each animal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670dedde-cc4f-405f-8689-20e9444c4765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:08:39.238378Z",
     "iopub.status.busy": "2022-04-14T22:08:39.237816Z",
     "iopub.status.idle": "2022-04-14T22:08:39.400869Z",
     "shell.execute_reply": "2022-04-14T22:08:39.400155Z",
     "shell.execute_reply.started": "2022-04-14T22:08:39.238316Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3094d0117c1a48e0947fab87ecea5ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –†–∞–∑–º–µ—á–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
    "ji.Innotater(\n",
    "    [\n",
    "        ji.ImageInnotation(images), # Display the image itself\n",
    "        ji.TextInnotation(images, multiline=False) # Display the image filename\n",
    "    ],\n",
    "    [\n",
    "        ji.BinaryClassInnotation(targets_exclude, name='Exclude'), # Checkbox\n",
    "        ji.RepeatInnotation(\n",
    "            (ji.BoundingBoxInnotation, targets_bboxes), # Individual animal bounding box\n",
    "            (ji.MultiClassInnotation, targets_breed,\n",
    "                {'name':'Breed', 'classes':breeds, 'dropdown':True}), # Per-animal breed dropdown\n",
    "            max_repeats=repeats, min_repeats=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e47090-6731-417d-98c1-3ec736567c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:09:44.976668Z",
     "iopub.status.busy": "2022-04-14T22:09:44.975987Z",
     "iopub.status.idle": "2022-04-14T22:09:44.984918Z",
     "shell.execute_reply": "2022-04-14T22:09:44.983790Z",
     "shell.execute_reply.started": "2022-04-14T22:09:44.976624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xywh2yolo(xywh, size):\n",
    "    x, y, w, h = xywh\n",
    "    x += w / 2\n",
    "    y += h / 2\n",
    "    x = x / size[1]\n",
    "    w = w / size[1]\n",
    "    y = y / size[0]\n",
    "    h = h / size[0]\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59aded89-6f3a-4edb-b3ae-0b2ce69cff99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T22:10:51.786878Z",
     "iopub.status.busy": "2022-04-14T22:10:51.785829Z",
     "iopub.status.idle": "2022-04-14T22:10:51.867388Z",
     "shell.execute_reply": "2022-04-14T22:10:51.866856Z",
     "shell.execute_reply.started": "2022-04-14T22:10:51.786750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Yolo\n",
    "result = []\n",
    "cache = root.replace('/images/', '/labels.cache')\n",
    "if os.path.exists(cache):\n",
    "    os.unlink(cache)\n",
    "    \n",
    "for im, bboxs in zip(images, targets_bboxes):\n",
    "    annotation = '.'.join(im.replace('/images/', '/labels/').split('.')[:-1]) + '.txt'\n",
    "    image = cv2.imread(im, cv2.IMREAD_COLOR)\n",
    "    with open(annotation, 'wt') as f:\n",
    "        for bbox in bboxs:\n",
    "            if bbox.sum() == 0:\n",
    "                continue\n",
    "            xywh = xywh2yolo(bbox.astype(np.float32), image.shape)\n",
    "            xywh = ' '.join([\"{:.6f}\".format(x) for x in xywh])\n",
    "            f.write('{} {}\\n'.format(15, xywh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0aadf733-1053-4a4c-94d5-a7f6864759a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T21:55:19.289491Z",
     "iopub.status.busy": "2022-04-14T21:55:19.287414Z",
     "iopub.status.idle": "2022-04-14T21:55:19.315898Z",
     "shell.execute_reply": "2022-04-14T21:55:19.314518Z",
     "shell.execute_reply.started": "2022-04-14T21:55:19.289393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'path': '../datasets/custom/',\n",
    "    'train': 'images',\n",
    "    'val': 'images',\n",
    "    # 'test': None,\n",
    "    'nc': 80,\n",
    "    # 'nc': 1,\n",
    "    # 'names': ['custom_object']\n",
    "    'names': ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush'] \n",
    "}\n",
    "# config['names'] = str(config['names'])\n",
    "with open('./config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4797d0a0-3e2a-43d5-8ddf-0ffdf91cc5e3",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-04-14T21:55:19.938658Z",
     "iopub.status.busy": "2022-04-14T21:55:19.936390Z",
     "iopub.status.idle": "2022-04-14T21:56:50.627105Z",
     "shell.execute_reply": "2022-04-14T21:56:50.624868Z",
     "shell.execute_reply.started": "2022-04-14T21:55:19.938477Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=models/yolov5m.pt, cfg=, data=config.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use `git pull` or `git clone git@github.com:AsciiShell/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.1-119-gaa542ce torch 1.11.0+cu102 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1    343485  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 369 layers, 21190557 parameters, 21190557 gradients, 49.1 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from models/yolov5m.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/asciishell/projects/hse-fsod/datasets/custom/labels' imag\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/asciishell/projects/hse-fsod/datasets/custom/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 219.90it/s\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/asciishell/projects/hse-fsod/datasets/custom/labels.cache' \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 56.66it/s]  \u001b[0m\n",
      "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.20 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/2        0G   0.02961   0.03518   0.06495        30       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8         10          1        0.9      0.907       0.58\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/2        0G   0.02229   0.02689   0.06405        24       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8         10          1        0.9       0.91      0.597\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/2        0G   0.03151   0.03237   0.07074        25       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8         10          1        0.9      0.911      0.602\n",
      "\n",
      "3 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 42.9MB\n",
      "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 42.9MB\n",
      "\n",
      "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 21172173 parameters, 0 gradients, 49.0 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          8         10          1        0.9      0.911      0.602\n",
      "                 cat          8         10          1        0.9      0.911      0.602\n",
      "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n",
      "Exception ignored in: <function StorageWeakRef.__del__ at 0x7f2471d6b9d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 36, in __del__\n",
      "  File \"/home/asciishell/projects/hse-fsod/venv/lib/python3.8/site-packages/torch/storage.py\", line 520, in _free_weak_ref\n",
      "AttributeError: 'NoneType' object has no attribute '_free_weak_ref'\n"
     ]
    }
   ],
   "source": [
    "!/home/asciishell/projects/hse-fsod/venv/bin/python \\\n",
    "    yolov5/train.py \\\n",
    "    --img 640 \\\n",
    "    --batch 16 \\\n",
    "    --epochs 3 \\\n",
    "    --data config.yaml \\\n",
    "    --weights models/yolov5m.pt \\\n",
    "    --cache \n",
    "    # --freeze 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00374db0-fd50-4781-98ef-03b3a9a59536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T21:56:50.633131Z",
     "iopub.status.busy": "2022-04-14T21:56:50.632113Z",
     "iopub.status.idle": "2022-04-14T21:56:51.106440Z",
     "shell.execute_reply": "2022-04-14T21:56:51.105664Z",
     "shell.execute_reply.started": "2022-04-14T21:56:50.633005Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 290 layers, 21172173 parameters, 0 gradients, 49.0 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model2 = AutoShape(DetectMultiBackend(\"./yolov5/runs/train/exp2/weights/best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d30db3af-ae34-4adb-bcd4-4594f3e2df77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T21:56:51.107958Z",
     "iopub.status.busy": "2022-04-14T21:56:51.107346Z",
     "iopub.status.idle": "2022-04-14T21:56:51.471076Z",
     "shell.execute_reply": "2022-04-14T21:56:51.469401Z",
     "shell.execute_reply.started": "2022-04-14T21:56:51.107928Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.687256</td>\n",
       "      <td>13.568044</td>\n",
       "      <td>493.835266</td>\n",
       "      <td>371.385132</td>\n",
       "      <td>0.803403</td>\n",
       "      <td>15</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.056463</td>\n",
       "      <td>13.806772</td>\n",
       "      <td>139.548264</td>\n",
       "      <td>370.451660</td>\n",
       "      <td>0.365682</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        xmin       ymin        xmax        ymax  confidence  class   name\n",
       "0  35.687256  13.568044  493.835266  371.385132    0.803403     15    cat\n",
       "1   1.056463  13.806772  139.548264  370.451660    0.365682     56  chair"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images[0]).pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a910788-de05-4e42-a89f-00556c85378e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T21:56:51.473065Z",
     "iopub.status.busy": "2022-04-14T21:56:51.472673Z",
     "iopub.status.idle": "2022-04-14T21:56:51.851389Z",
     "shell.execute_reply": "2022-04-14T21:56:51.850611Z",
     "shell.execute_reply.started": "2022-04-14T21:56:51.473029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.570694</td>\n",
       "      <td>9.221554</td>\n",
       "      <td>491.663361</td>\n",
       "      <td>374.221100</td>\n",
       "      <td>0.707715</td>\n",
       "      <td>15</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.815825</td>\n",
       "      <td>140.598206</td>\n",
       "      <td>374.720581</td>\n",
       "      <td>0.427241</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        xmin      ymin        xmax        ymax  confidence  class   name\n",
       "0  35.570694  9.221554  491.663361  374.221100    0.707715     15    cat\n",
       "1   0.000000  9.815825  140.598206  374.720581    0.427241     56  chair"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(images[0]).pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a78f9-2fc8-451b-9e08-37f8752ca763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YoloV5)",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
